{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport heapq\n\n# Set the random seed for reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\nimport warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:38.155398Z",
          "iopub.execute_input": "2024-09-10T22:28:38.155981Z",
          "iopub.status.idle": "2024-09-10T22:28:38.194752Z",
          "shell.execute_reply.started": "2024-09-10T22:28:38.155934Z",
          "shell.execute_reply": "2024-09-10T22:28:38.193366Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Define the possible actions for the drones\nACTIONS = [\n    (0, 1),   # Move right\n    (1, 0),   # Move down\n    (0, -1),  # Move left\n    (-1, 0)   # Move up\n]\n\n# Simulation parameters\nGRID_SIZE = 10  # 10x10 grid\nNUM_DRONES = 3  # Number of drones\nMAX_STEPS = 50  # Maximum steps for the simulation\nENERGY_CONSUMPTION_PER_MOVE = 1  # Energy consumed per move\nALPHA = 0.1  # Learning rate\nGAMMA = 0.9  # Discount factor\nEPSILON = 0.1  # Epsilon-greedy policy for exploration\nMIN_EPSILON = 0.01  # Minimum epsilon value for exploration\nEPSILON_DECAY = 0.99  # Decay rate for epsilon\nINITIAL_BATTERY = 100  # Initial battery percentage for each drone\nRECHARGE_THRESHOLD = 20  # Battery level below which drones need to recharge\nRECHARGE_STATION = (GRID_SIZE - 1, GRID_SIZE - 1)  # Recharging station location\nRECHARGE_TIME = 10  # Number of moves to fully recharge\nSAFE_DISTANCE = 1  # Minimum safe distance between drones\n\n# Initialize metrics for tracking simulation performance\naccidents_over_time = []  # Track accidents over time\nenergy_usage_over_time = []  # Track energy usage over time\nunique_coverage_over_time = []  # Track unique coverage over time\nepsilon_over_time = []  # Track epsilon decay over time\nredundant_coverage_over_time = []  # Track redundant coverage over time\ncollision_rate = []  # Collision rate (accidents per step)\ncoverage_efficiency = []  # Coverage efficiency (percentage of unique cells covered per move)\nsuccess_rate = []  # Success rate for simulations reaching over 90% coverage\ncumulative_unique_coverage = []  # Cumulative unique coverage over multiple simulations\n\n# Initialize lists to store results from each simulation\nall_accidents_over_time = []\nall_energy_usage_over_time = []\nall_unique_coverage_over_time = []\nall_epsilon_over_time = []\nall_redundant_coverage_over_time = []\nall_collision_rate = []\nall_coverage_efficiency = []\nall_success_rate = []",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:38.197210Z",
          "iopub.execute_input": "2024-09-10T22:28:38.197665Z",
          "iopub.status.idle": "2024-09-10T22:28:38.211400Z",
          "shell.execute_reply.started": "2024-09-10T22:28:38.197611Z",
          "shell.execute_reply": "2024-09-10T22:28:38.209742Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Environment:\n    \"\"\"\n    Environment class to manage the grid and track the state of the simulation.\n    \"\"\"\n    def __init__(self, grid_size, num_drones):\n        self.grid_size = grid_size\n        self.grid = np.zeros((grid_size, grid_size))\n        self.coverage_count = np.zeros((grid_size, grid_size), dtype=int)\n        self.coverage_map = np.zeros((grid_size, grid_size), dtype=int)\n        self.drones = [Drone(i, grid_size, INITIAL_BATTERY, RECHARGE_STATION) for i in range(num_drones)]\n        self.accidents = 0\n\n    def reset(self):\n        \"\"\"\n        Reset the environment to its initial state.\n        \"\"\"\n        self.grid.fill(0)\n        self.coverage_count.fill(0)\n        self.coverage_map.fill(0)\n        self.accidents = 0\n        for drone in self.drones:\n            drone.reset()\n\n    def update_coverage(self, position):\n        \"\"\"\n        Update the grid coverage based on drone positions.\n\n        Parameters:\n        - position: Tuple, current position of the drone\n        \"\"\"\n        x, y = position\n        self.grid[x, y] = 1\n        self.coverage_count[x, y] += 1\n        self.coverage_map[x, y] = 1\n\n    def check_accidents(self):\n        \"\"\"\n        Check for accidents where multiple drones occupy the same cell.\n        \"\"\"\n        positions = [drone.position for drone in self.drones]\n        if len(positions) != len(set(positions)):\n            self.accidents += 1\n\n    def step(self):\n        \"\"\"\n        Perform a single step in the simulation, updating drone states and grid coverage.\n        \"\"\"\n        for drone in self.drones:\n            drone.act(self.grid, self.coverage_count, self.coverage_map, self.drones)\n            self.update_coverage(drone.position)\n        self.check_accidents()\n\n\nclass Drone:\n    \"\"\"\n    Drone class representing each agent in the environment.\n    \"\"\"\n    def __init__(self, drone_id, grid_size, initial_battery, recharge_station):\n        self.id = drone_id\n        self.grid_size = grid_size\n        self.position = (0, 0)\n        self.battery = initial_battery\n        self.q_table = np.zeros((grid_size, grid_size, len(ACTIONS)))\n        self.epsilon = EPSILON\n        self.steps_to_recharge = 0\n        self.recharge_station = recharge_station\n        self.covered = set()\n\n    def reset(self):\n        \"\"\"\n        Reset the drone to its initial state.\n        \"\"\"\n        self.position = (0, 0)\n        self.battery = INITIAL_BATTERY\n        self.steps_to_recharge = 0\n        self.epsilon = EPSILON\n        self.covered.clear()\n        self.q_table.fill(0)\n\n    def update_epsilon(self):\n        \"\"\"\n        Decays epsilon over time to reduce exploration as learning progresses.\n        \"\"\"\n        self.epsilon = max(MIN_EPSILON, self.epsilon * EPSILON_DECAY)\n        epsilon_over_time.append(self.epsilon)\n\n    def choose_action(self, coverage_map):\n        \"\"\"\n        Chooses an action based on an epsilon-greedy policy, prioritizing unexplored cells.\n\n        Parameters:\n        - coverage_map: 2D numpy array representing the coverage status of the grid\n\n        Returns:\n        - Int, index of the chosen action\n        \"\"\"\n        x, y = self.position\n\n        if random.uniform(0, 1) < self.epsilon:\n            # Explore: choose a random action\n            return random.randint(0, len(ACTIONS) - 1)\n        else:\n            # Exploit: choose the best action based on Q-table\n            uncovered_actions = [(i, (x + dx, y + dy)) for i, (dx, dy) in enumerate(ACTIONS)\n                                 if 0 <= x + dx < self.grid_size and 0 <= y + dy < self.grid_size and coverage_map[x + dx, y + dy] == 0]\n            if uncovered_actions:\n                # Prefer actions that lead to uncovered cells\n                return random.choice([action[0] for action in uncovered_actions])\n            else:\n                # If all adjacent cells are covered, choose based on Q-table\n                return np.argmax(self.q_table[x, y])\n\n    def act(self, grid, coverage_count, coverage_map, drones):\n        \"\"\"\n        Execute an action based on the chosen policy and update the drone's state.\n\n        Parameters:\n        - grid: 2D numpy array representing the grid\n        - coverage_count: 2D numpy array tracking the number of times each cell is covered\n        - coverage_map: 2D numpy array indicating whether each cell is covered\n        - drones: List of Drone objects representing all drones in the simulation\n        \"\"\"\n        global total_recharge_time, total_recharging_drones, total_recharge_events, accidents\n\n        if self.battery <= 0:\n            return  # Can't move if out of battery\n\n        if self.steps_to_recharge > 0:\n            # Handle recharging\n            self.steps_to_recharge -= 1\n            if self.steps_to_recharge == 0:\n                self.battery = INITIAL_BATTERY\n                total_recharging_drones += 1\n            return\n\n        if self.battery < RECHARGE_THRESHOLD:\n            path_to_recharge = a_star_path(self.position, self.recharge_station, self.grid_size)\n            if path_to_recharge:\n                next_position = path_to_recharge[0]\n                if next_position == self.recharge_station:\n                    self.steps_to_recharge = RECHARGE_TIME\n                    total_recharge_events += 1\n                else:\n                    self.position = next_position\n            else:\n                dx, dy = np.sign(self.recharge_station[0] - self.position[0]), np.sign(self.recharge_station[1] - self.position[1])\n                self.position = (self.position[0] + dx, self.position[1] + dy)\n            self.battery -= ENERGY_CONSUMPTION_PER_MOVE\n            return\n\n        action = self.choose_action(coverage_map)\n        dx, dy = ACTIONS[action]\n        new_position = (self.position[0] + dx, self.position[1] + dy)\n\n        if not (0 <= new_position[0] < self.grid_size and 0 <= new_position[1] < self.grid_size):\n            return  # Stay in place if out of bounds\n\n        # Check for safe distance from other drones\n        if any(np.linalg.norm(np.array(new_position) - np.array(drone.position)) < SAFE_DISTANCE for drone in drones if drone.id != self.id):\n            return  # Skip move if it's not safe\n\n        # Check for accidents (drones in the same grid cell)\n        if any(drone.position == new_position for drone in drones if drone.id != self.id):\n            accidents += 1\n            return  # Skip move if another drone is already there\n\n        # Calculate reward and update Q-table\n        reward = 10 if new_position not in self.covered else -5\n        reward -= ENERGY_CONSUMPTION_PER_MOVE\n        old_q_value = self.q_table[self.position[0], self.position[1], action]\n        future_q_value = np.max(self.q_table[new_position[0], new_position[1]])\n        self.q_table[self.position[0], self.position[1], action] = (1 - ALPHA) * old_q_value + ALPHA * (reward + GAMMA * future_q_value)\n\n        # Update position, battery, and coverage\n        self.position = new_position\n        self.battery -= ENERGY_CONSUMPTION_PER_MOVE\n        self.covered.add(self.position)\n        grid[self.position] = 1\n        coverage_count[self.position] += 1\n        coverage_map[self.position] = 1\n        self.update_epsilon()  # Update epsilon adaptively\n\n\nclass MARL:\n    \"\"\"\n    Multi-Agent Reinforcement Learning class to manage learning across multiple drones.\n    \"\"\"\n    def __init__(self, environment):\n        self.environment = environment\n\n    def train(self, max_steps):\n        \"\"\"\n        Train the drone swarm using MARL over a specified number of steps.\n\n        Parameters:\n        - max_steps: Int, maximum number of steps for the simulation\n        \"\"\"\n        cumulative_energy_used = 0\n        total_accidents = 0\n\n        for step in range(max_steps):\n            self.environment.step()\n            \n            # Track accidents, energy usage, and redundant coverage over time\n            total_accidents += self.environment.accidents\n            collision_rate.append(total_accidents / (step + 1)) # Calculate collision rate (accidents per step)\n            \n            current_coverage = np.sum(self.environment.grid)\n            cumulative_unique_coverage.append(current_coverage)\n            \n            # Calculate coverage efficiency (percentage of unique cells covered per move)\n            if step > 0:\n                efficiency = current_coverage / step\n                coverage_efficiency.append(efficiency)\n\n            accidents_over_time.append(self.environment.accidents)\n            cumulative_energy_used += sum(INITIAL_BATTERY - drone.battery for drone in self.environment.drones)\n            energy_usage_over_time.append(cumulative_energy_used)\n            unique_coverage_over_time.append(np.sum(self.environment.grid))\n            redundant_coverage_over_time.append(np.sum(self.environment.coverage_count) - np.sum(self.environment.grid))\n\n            if np.all(self.environment.grid):\n                print(f\"All cells covered in {step + 1} steps\")\n                break\n        \n        # Calculate success rate (percentage of simulations reaching over 90% coverage)\n        if current_coverage >= 0.9 * (self.environment.grid_size * self.environment.grid_size):\n            success_rate.append(1)\n        else:\n            success_rate.append(0)\n\ndef a_star_path(start, goal, grid_size):\n    \"\"\"\n    Returns the shortest path from start to goal using A* algorithm.\n    \n    Parameters:\n    - start: Tuple, starting coordinates (x, y)\n    - goal: Tuple, goal coordinates (x, y)\n    - grid_size: Int, size of the grid\n\n    Returns:\n    - List of tuples representing the path from start to goal.\n    \"\"\"\n    def heuristic(a, b):\n        \"\"\"Heuristic function for A* (Manhattan distance).\"\"\"\n        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n\n    open_set = []\n    heapq.heappush(open_set, (0, start))\n    came_from = {}\n    g_score = {start: 0}\n    f_score = {start: heuristic(start, goal)}\n\n    while open_set:\n        current = heapq.heappop(open_set)[1]\n\n        if current == goal:\n            path = []\n            while current in came_from:\n                path.append(current)\n                current = came_from[current]\n            return path[::-1]\n\n        for dx, dy in ACTIONS:\n            neighbor = (current[0] + dx, current[1] + dy)\n            if 0 <= neighbor[0] < grid_size and 0 <= neighbor[1] < grid_size:\n                tentative_g_score = g_score[current] + 1\n                if tentative_g_score < g_score.get(neighbor, float('inf')):\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g_score\n                    f_score[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n                    heapq.heappush(open_set, (f_score[neighbor], neighbor))\n    return []\n\n\ndef generate_start_positions(num_positions, grid_size):\n    \"\"\"\n    Generates random start positions for drones on the grid.\n\n    Parameters:\n    - num_positions: Int, number of positions to generate\n    - grid_size: Int, size of the grid\n\n    Returns:\n    - List of tuples representing start positions.\n    \"\"\"\n    positions = set()\n    while len(positions) < num_positions:\n        x = random.randint(0, grid_size - 1)\n        y = random.randint(0, grid_size - 1)\n        positions.add((x, y))\n    return list(positions)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:38.292132Z",
          "iopub.execute_input": "2024-09-10T22:28:38.292520Z",
          "iopub.status.idle": "2024-09-10T22:28:38.349008Z",
          "shell.execute_reply.started": "2024-09-10T22:28:38.292481Z",
          "shell.execute_reply": "2024-09-10T22:28:38.346938Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Initialize environment and MARL\nenvironment = Environment(GRID_SIZE, NUM_DRONES)\nmarl = MARL(environment)\n\n# Train the swarm with MARL\nmarl.train(MAX_STEPS)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:38.352218Z",
          "iopub.execute_input": "2024-09-10T22:28:38.352722Z",
          "iopub.status.idle": "2024-09-10T22:28:38.379825Z",
          "shell.execute_reply.started": "2024-09-10T22:28:38.352660Z",
          "shell.execute_reply": "2024-09-10T22:28:38.378176Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Collect results\nunique_covered_cells = np.sum(environment.grid)\ntotal_visits = np.sum(environment.coverage_count)\ngrid_coverage_percentage = (unique_covered_cells / (GRID_SIZE * GRID_SIZE)) * 100\nredundant_coverage = total_visits - unique_covered_cells\nredundant_coverage_percentage = (redundant_coverage / total_visits) * 100 if total_visits > 0 else 0\n\nenergy_used = sum(INITIAL_BATTERY - drone.battery for drone in environment.drones)\nenergy_efficiency = energy_used / unique_covered_cells if unique_covered_cells > 0 else float('inf')\nenergy_used_percentage = (energy_used / (NUM_DRONES * INITIAL_BATTERY)) * 100\n\n# Print metrics\nprint(f\"Total covered cells: {unique_covered_cells}\")\nprint(f\"Total energy used: {energy_used}\")\nprint(f\"Percentage of grid covered: {grid_coverage_percentage:.2f}%\")\nprint(f\"Redundant coverage: {redundant_coverage}\")\nprint(f\"Percentage of redundant coverage: {redundant_coverage_percentage:.2f}%\")\nprint(f\"Energy Efficiency (energy per covered cell): {energy_efficiency:.2f}\")\nprint(f\"Energy used out of total available energy: {energy_used_percentage:.2f}%\")\nprint(f\"Number of accidents (drones in the same cell): {environment.accidents}\")\n\n# Print new metrics\nif len(collision_rate) > 0:\n    avg_collision_rate = sum(collision_rate) / len(collision_rate)\nelse:\n    avg_collision_rate = 0\nprint(f\"Average Collision Rate (accidents per step): {avg_collision_rate:.2f}\")\n\nif len(coverage_efficiency) > 0:\n    avg_coverage_efficiency = sum(coverage_efficiency) / len(coverage_efficiency)\nelse:\n    avg_coverage_efficiency = 0\nprint(f\"Average Coverage Efficiency (percentage of unique cells covered per move): {avg_coverage_efficiency:.2f}%\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:38.382423Z",
          "iopub.execute_input": "2024-09-10T22:28:38.383254Z",
          "iopub.status.idle": "2024-09-10T22:28:38.397367Z",
          "shell.execute_reply.started": "2024-09-10T22:28:38.383198Z",
          "shell.execute_reply": "2024-09-10T22:28:38.395482Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Visualizations\n\n# 1. Coverage Heatmap\nplt.imshow(environment.grid, cmap='Greens')\nplt.title('Grid Coverage')\nplt.colorbar(label='Coverage Status')\nplt.show()\n\n# 2. Redundancy Heatmap\nplt.imshow(environment.coverage_count, cmap='hot', interpolation='nearest')\nplt.title('Redundancy Heatmap')\nplt.colorbar(label='Number of Times Covered')\nplt.show()\n\n# 3. Accidents Over Time\nplt.plot(accidents_over_time)\nplt.title('Accidents Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Number of Accidents')\nplt.show()\n\n# 4. Energy Usage Over Time\nplt.plot(energy_usage_over_time)\nplt.title('Energy Usage Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Total Energy Used')\nplt.show()\n\n# 5. Epsilon Decay Over Time\nplt.plot(epsilon_over_time)\nplt.title('Epsilon Decay Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Epsilon')\nplt.show()\n\n# 6. Unique Coverage Over Time\nplt.plot(unique_coverage_over_time)\nplt.title('Unique Coverage Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Unique Cells Covered')\nplt.show()\n\n# 7. Redundant Coverage Over Time\nplt.plot(redundant_coverage_over_time)\nplt.title('Redundant Coverage Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Redundant Coverage')\nplt.show()\n\n# 8. Collision Rate Over Time\nplt.plot(collision_rate)\nplt.title('Collision Rate Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Collision Rate')\nplt.show()\n\n# 9. Cumulative Unique Coverage Over Time\nplt.plot(cumulative_unique_coverage)\nplt.title('Cumulative Unique Coverage Over Time')\nplt.xlabel('Simulation Step')\nplt.ylabel('Cumulative Unique Coverage')\nplt.show()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:38.400018Z",
          "iopub.execute_input": "2024-09-10T22:28:38.401160Z",
          "iopub.status.idle": "2024-09-10T22:28:41.420569Z",
          "shell.execute_reply.started": "2024-09-10T22:28:38.401100Z",
          "shell.execute_reply": "2024-09-10T22:28:41.418409Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Number of simulations to run\nNUM_SIMULATIONS = 100\n\n# Initialize lists to store results from each simulation\nall_accidents_over_time = []\nall_energy_usage_over_time = []\nall_unique_coverage_over_time = []\nall_epsilon_over_time = []\nall_redundant_coverage_over_time = []\nall_collision_rate = []\nall_coverage_efficiency = []\nall_success_rate = []\n\nfor simulation in range(NUM_SIMULATIONS):\n    # Initialize environment and MARL\n    environment = Environment(GRID_SIZE, NUM_DRONES)\n    marl = MARL(environment)\n\n    # Train the swarm with MARL\n    marl.train(MAX_STEPS)\n\n    # Store metrics for each simulation\n    all_accidents_over_time.append(accidents_over_time[:])\n    all_energy_usage_over_time.append(energy_usage_over_time[:])\n    all_unique_coverage_over_time.append(unique_coverage_over_time[:])\n    all_epsilon_over_time.append(epsilon_over_time[:])\n    all_redundant_coverage_over_time.append(redundant_coverage_over_time[:])\n    all_collision_rate.append(collision_rate[:])\n    all_coverage_efficiency.append(coverage_efficiency[:])\n    all_success_rate.append(success_rate[:])\n\n    # Reset lists for the next simulation\n    accidents_over_time = []\n    energy_usage_over_time = []\n    unique_coverage_over_time = []\n    epsilon_over_time = []\n    redundant_coverage_over_time = []\n    collision_rate = []\n    coverage_efficiency = []\n    success_rate = []\n\n# After all simulations, calculate averages or summaries\navg_collision_rate = np.mean([np.mean(rate) for rate in all_collision_rate if rate])\navg_coverage_efficiency = np.mean([np.mean(efficiency) for efficiency in all_coverage_efficiency if efficiency])\n# overall_success_rate = np.mean([np.mean(success) for success in all_success_rate if success])\n\nprint(f\"Average Collision Rate (accidents per step) across all simulations: {avg_collision_rate:.2f}%\")\nprint(f\"Average Coverage Efficiency (percentage of unique cells covered per move) across all simulations: {avg_coverage_efficiency:.2f}%\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-10T22:28:41.424346Z",
          "iopub.execute_input": "2024-09-10T22:28:41.424841Z",
          "iopub.status.idle": "2024-09-10T22:28:42.443691Z",
          "shell.execute_reply.started": "2024-09-10T22:28:41.424762Z",
          "shell.execute_reply": "2024-09-10T22:28:42.442060Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
